import os
import re
import yaml
import base64
import json
import random
import emoji
import ipaddress
from urllib.parse import unquote, urlparse, parse_qs

# -------------------------------
# ğŸ”§ æ¸…æ´—èŠ‚ç‚¹å
# -------------------------------
def clean_name(name: str) -> str:
    name = name.replace('ğŸ‡¨ğŸ‡³TW', 'ğŸ‡¹ğŸ‡¼TW')
    name = re.sub(r'[_\s]*@wangcai_8[_\s]*', ' ', name, flags=re.IGNORECASE)
    name = re.sub(r'\s+', ' ', name).strip()
    return name

# -------------------------------
# ğŸ§© Base64 è‡ªåŠ¨è§£ç 
# -------------------------------
def try_base64_decode(content: str) -> str:
    try:
        if not re.match(r'^[A-Za-z0-9+/=\r\n]+$', content.strip()):
            return content
        decoded = base64.b64decode(content.strip()).decode('utf-8', errors='ignore')
        if any(proto in decoded for proto in ['ss://', 'vmess://', 'trojan://', 'vless://']):
            print("âœ… è‡ªåŠ¨è¯†åˆ«å¹¶è§£ç  Base64 æ–‡ä»¶")
            return decoded
        return content
    except Exception:
        return content

# -------------------------------
# ğŸ” URL ç±»å‹èŠ‚ç‚¹åˆ¤æ–­
# -------------------------------
def is_url_node_file(content: str) -> bool:
    lines = [l.strip() for l in content.splitlines() if l.strip()]
    if not lines:
        return False
    return all(l.startswith(('ss://','vmess://','vless://','trojan://')) for l in lines)

# -------------------------------
# ğŸ“¦ æå– Clash proxies å—
# -------------------------------
def extract_proxies_block(filepath):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {filepath} ({e})")
        return None

    proxies_lines = []
    in_proxies = False
    proxies_indent = None

    for line in lines:
        if not in_proxies:
            if re.match(r'^\s*proxies\s*:\s*$', line):
                in_proxies = True
                proxies_indent = len(line) - len(line.lstrip())
                proxies_lines.append(line)
        else:
            indent = len(line) - len(line.lstrip())
            if indent <= proxies_indent and line.strip() != '':
                break
            proxies_lines.append(line)

    return ''.join(proxies_lines) if proxies_lines else None

# -------------------------------
# ğŸ§­ æå–æ——å¸œä¸åœ°åŒº
# -------------------------------
def extract_region(name):
    match = re.match(r'^([\U0001F1E6-\U0001F1FF]{2})([A-Z]{2,})', name)
    if match:
        return match.group(1), match.group(2)

    all_emojis = emoji.EMOJI_DATA.keys()
    for e in all_emojis:
        if name.startswith(e):
            remain = name[len(e):]
            match_region = re.match(r'^([A-Z]{2,})', remain)
            if match_region:
                return e, match_region.group(1)
    return 'ğŸ³ï¸', 'ZZ'

# -------------------------------
# ğŸ”¢ æ£€æŸ¥ IP æ˜¯å¦è¿ç»­
# -------------------------------
def check_ip_sequence(proxies):
    ips = []
    for p in proxies:
        ip = p.get('server')
        try:
            ip_obj = ipaddress.ip_address(ip)
            ips.append(int(ip_obj))
        except:
            return False
    ips.sort()
    return len(ips) == 256 and ips[-1] - ips[0] == 255

# -------------------------------
# ğŸ˜ Emoji å·¥å…·
# -------------------------------
def is_flag_emoji(e):
    return re.match(r'^[ğŸ‡¦-ğŸ‡¿]{2}$', e)

def load_available_emojis():
    all_emojis = emoji.EMOJI_DATA.keys()
    return [e for e in all_emojis if not is_flag_emoji(e)]

def generate_unique_emoji(used_emojis, available_emojis):
    choice = random.choice([e for e in available_emojis if e not in used_emojis])
    used_emojis.add(choice)
    return choice

# -------------------------------
# ğŸ” åˆ¤æ–­ Clash æ–‡ä»¶æ˜¯å¦åŒ…å«å¯ç”¨èŠ‚ç‚¹
# -------------------------------
def detect_node_file(content: str) -> bool:
    node_keywords = ['ss://', 'vmess://', 'trojan://', 'vless://']
    if any(k in content for k in node_keywords):
        return True
    if 'proxies:' in content:
        try:
            data = yaml.safe_load(content)
            proxies = data.get('proxies', [])
            for p in proxies:
                p_type = str(p.get('type','')).lower()
                if p_type not in ['direct','reject','blackhole']:
                    return True
        except Exception:
            return False
    return False

# -------------------------------
# âš¡ URL ç±»å‹èŠ‚ç‚¹æ–‡ä»¶å¤„ç†ï¼ˆæœºåœºè®¢é˜…ï¼‰
# -------------------------------
def process_url_file(filepath, output_filename, used_emojis, available_emojis):
    print(f"ğŸ”¹ å¤„ç† URL ç±»å‹èŠ‚ç‚¹æ–‡ä»¶: {filepath}")
    with open(filepath,'r',encoding='utf-8') as f:
        lines = [l.strip() for l in f.readlines() if l.strip()]

    node_count = len(lines)
    emoji_prefix = generate_unique_emoji(used_emojis, available_emojis)
    print(f"âœ¨ é€‰ç”¨ emoji: {emoji_prefix}")

    # åˆ†åœ°åŒºåˆ†ç»„
    region_groups = {}
    parsed_nodes = []
    for idx, url in enumerate(lines):
        if '#' in url:
            base, remark = url.split('#',1)
            remark = unquote(remark)
        else:
            base, remark = url, 'Unnamed'
        flag, region = extract_region(remark)
        region_groups.setdefault((flag, region), []).append((idx, base, remark))

    # æŒ‰åœ°åŒº + emoji + ç¼–å·ç”Ÿæˆæ–° remark
    new_lines = []
    for (flag, region), group in region_groups.items():
        num_len = 2 if node_count <= 100 else 3
        for seq_idx, (orig_idx, base, remark) in enumerate(group, start=1):
            seq = str(seq_idx).zfill(num_len)
            new_remark = f"{emoji_prefix}{node_count}{flag}{region}_{seq}"
            new_url = f"{base}#{new_remark}"
            new_lines.append(new_url)

    # è¾“å‡º Base64
    content_str = '\n'.join(new_lines)
    b64_content = base64.b64encode(content_str.encode()).decode()
    with open(output_filename,'w',encoding='utf-8') as f:
        f.write(b64_content)

    print(f"âœ… ç”Ÿæˆæœºåœºè®¢é˜…æ–‡ä»¶: {output_filename}, èŠ‚ç‚¹æ•°: {node_count}")

# -------------------------------
# ğŸ”¨ Clash æ–‡ä»¶å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
# -------------------------------
def process_clash_file(filepath, output_filename, used_emojis, available_emojis):
    print(f"ğŸ”¹ å¤„ç† Clash æ–‡ä»¶: {filepath}")

    proxies_text = extract_proxies_block(filepath)
    if not proxies_text:
        print(f"âš ï¸ æœªæ‰¾åˆ° proxies å—: {filepath}")
        return

    data = yaml.safe_load(proxies_text)
    proxies = [p for p in data.get('proxies', []) if str(p.get('type','')).lower() not in ['direct','reject','blackhole']]
    if not proxies:
        print(f"âš ï¸ proxies èŠ‚ç‚¹ä¸ºç©ºæˆ–å…¨éƒ¨ä¸ºéä»£ç†èŠ‚ç‚¹: {filepath}")
        return

    node_count = len(proxies)
    types = set(p.get('type', 'unknown') for p in proxies)
    node_type = types.pop() if len(types) == 1 else 'Mix'
    emoji_prefix = generate_unique_emoji(used_emojis, available_emojis)
    ip_regular = check_ip_sequence(proxies)

    region_groups = {}
    for p in proxies:
        p['name'] = clean_name(p.get('name','Unnamed'))
        flag, region = extract_region(p['name'])
        key = (flag, region)
        region_groups.setdefault(key, []).append(p)

    for (flag, region), group in region_groups.items():
        group_size = len(group)
        num_len = 2 if node_count <= 100 else 3
        if ip_regular and group_size == 256:
            def ip_last_octet(proxy):
                try:
                    ip = ipaddress.ip_address(proxy.get('server'))
                    return int(str(ip).split('.')[-1])
                except:
                    return 999
            group_sorted = sorted(group, key=ip_last_octet)
            start_num = 0
        else:
            group_sorted = group
            start_num = 1

        for idx, p in enumerate(group_sorted):
            seq = str(start_num + idx).zfill(num_len)
            new_name = f"{emoji_prefix}{node_count}{node_type}{flag}{region}_{seq}"
            p['name'] = new_name

    out = {'proxies': proxies}
    with open(output_filename,'w',encoding='utf-8') as f:
        yaml.dump(out,f,allow_unicode=True,sort_keys=False,default_flow_style=False)
    print(f"âœ… ç”Ÿæˆ Clash æ–‡ä»¶: {output_filename}, èŠ‚ç‚¹æ•°: {node_count}, ç±»å‹: {node_type}")

# -------------------------------
# ğŸ”¨ ä¸»å¤„ç†é€»è¾‘
# -------------------------------
def process_file(filepath, output_filename, used_emojis, available_emojis):
    with open(filepath,'r',encoding='utf-8') as f:
        raw_content = f.read()
    content = try_base64_decode(raw_content)

    if is_url_node_file(content):
        process_url_file(filepath, output_filename, used_emojis, available_emojis)
        return
    elif detect_node_file(content):
        process_clash_file(filepath, output_filename, used_emojis, available_emojis)
        return
    else:
        print(f"âš ï¸ è·³è¿‡éèŠ‚ç‚¹æ–‡ä»¶: {os.path.basename(filepath)}")

# -------------------------------
# ğŸš€ ä¸»å‡½æ•°å…¥å£
# -------------------------------
def main():
    upstream_dir = 'upstream_repo'
    files = sorted([f for f in os.listdir(upstream_dir) if os.path.isfile(os.path.join(upstream_dir, f))])

    available_emojis = load_available_emojis()
    used_emojis = set()

    file_idx = 1
    for file in files:
        filepath = os.path.join(upstream_dir, file)
        output_filename = f"suiyuan8_{file_idx:03}.yaml"
        process_file(filepath, output_filename, used_emojis, available_emojis)
        file_idx += 1

    print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

if __name__ == '__main__':
    main()
