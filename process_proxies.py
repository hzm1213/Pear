import os
import re
import base64
import yaml
from urllib.parse import unquote, urlparse

# =============================
# åŸºç¡€é…ç½®
# =============================

UPSTREAM_DIR = "upstream_repo"
OUTPUT_PREFIX = "suiyuan8_"
EMOJI_PREFIX = "ğŸ‘©ğŸ¾â€â¤â€ğŸ‘©ğŸ¼"

# =============================
# èŠ‚ç‚¹åè®®æ£€æµ‹æ­£åˆ™
# =============================

NODE_URL_PATTERN = re.compile(
    r'^(?:(vmess|vless|trojan|ss)://[A-Za-z0-9=_\-~%!:/?#@.,&+]+)', re.IGNORECASE
)

# =============================
# å·¥å…·å‡½æ•°
# =============================

def is_url_node_line(line: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦æ˜¯ URL èŠ‚ç‚¹"""
    return bool(NODE_URL_PATTERN.match(line.strip()))

def decode_base64(data: str) -> str:
    """è§£ç  Base64"""
    data = data.strip()
    # padding å¤„ç†
    missing_padding = len(data) % 4
    if missing_padding:
        data += "=" * (4 - missing_padding)
    try:
        return base64.b64decode(data).decode("utf-8", errors="ignore")
    except Exception:
        return data

def clean_name(name: str) -> str:
    """æ¸…ç†åç§°ä¸­æ— å…³ç¬¦å·"""
    name = unquote(name)
    name = re.sub(r'[@#%]', '', name)
    return name.strip()

def extract_region(name: str):
    """æå–åœ°åŒº flag + region ä»£ç """
    # å…ˆå°è¯• flag
    flag_match = re.findall(r'[\U0001F1E6-\U0001F1FF]{2}', name)
    flag = flag_match[0] if flag_match else "ğŸ³ï¸"

    # æå–ç®€å†™ï¼ˆSG, JP, US ç­‰ï¼‰
    region_match = re.search(r'(SG|JP|HK|TW|KR|US|UK|DE|FR|VN|TH|MY|IN|AU|CA|BR|RU|CN)', name, re.I)
    region = region_match.group(1).upper() if region_match else "ZZ"

    return flag, region

def parse_url_node(line: str):
    """è§£æ URL èŠ‚ç‚¹å¹¶è¿”å›ç»“æ„åŒ–ä¿¡æ¯"""
    line = line.strip()
    proto = line.split("://", 1)[0].lower()
    parsed = urlparse(line)
    name = unquote(parsed.fragment or "")
    name = clean_name(name)
    flag, region = extract_region(name)
    return {
        "raw": line,
        "type": proto.upper(),
        "name": name,
        "flag": flag,
        "region": region
    }

def parse_clash_yaml(path: str):
    """å°è¯•è§£æ Clash YAML é…ç½®"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = yaml.safe_load(f)
        if isinstance(data, dict) and "proxies" in data and isinstance(data["proxies"], list):
            return data["proxies"]
        return []
    except Exception:
        return []

# =============================
# æ ¸å¿ƒå¤„ç†é€»è¾‘
# =============================

def process_upstream_files():
    os.makedirs(UPSTREAM_DIR, exist_ok=True)
    files = os.listdir(UPSTREAM_DIR)
    node_files = []

    for file in files:
        path = os.path.join(UPSTREAM_DIR, file)
        if not os.path.isfile(path):
            continue

        # è¯»å–æ–‡ä»¶å†…å®¹
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            content = f.read().strip()

        # 1ï¸âƒ£ Base64 å†…å®¹å°è¯•è§£ç 
        if re.match(r'^[A-Za-z0-9+/=\n\r]+$', content) and not content.startswith("proxies:"):
            decoded = decode_base64(content)
            if is_url_node_line(decoded.splitlines()[0]):
                content = decoded

        # 2ï¸âƒ£ åˆ¤æ–­æ˜¯å¦ä¸º URL èŠ‚ç‚¹
        if any(is_url_node_line(line) for line in content.splitlines()):
            node_files.append((file, content, "url"))
            continue

        # 3ï¸âƒ£ åˆ¤æ–­æ˜¯å¦ä¸º Clash èŠ‚ç‚¹é…ç½®
        proxies = parse_clash_yaml(path)
        if proxies:
            node_files.append((file, proxies, "clash"))

    # 4ï¸âƒ£ å¤„ç†æ¯ä¸ªèŠ‚ç‚¹æ–‡ä»¶
    for file, data, ftype in node_files:
        base_name = os.path.splitext(os.path.basename(file))[0]
        output_file = f"{OUTPUT_PREFIX}{base_name}.yaml"

        if ftype == "url":
            # å¤„ç† URL èŠ‚ç‚¹
            nodes = []
            for line in data.splitlines():
                if is_url_node_line(line):
                    n = parse_url_node(line)
                    nodes.append(n)
            if not nodes:
                continue

            total = len(nodes)
            new_nodes = []
            for idx, n in enumerate(nodes, start=1):
                seq = str(idx).zfill(3 if total > 100 else 2)
                new_name = f"{EMOJI_PREFIX}{total}{n['type']}{n['flag']}{n['region']}_{seq}"
                n['name'] = new_name
                new_nodes.append(n["raw"].split("#")[0] + "#" + n["name"])

            # è¾“å‡ºä¸º Base64
            merged = "\n".join(new_nodes)
            encoded = base64.b64encode(merged.encode()).decode()
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(encoded)

        elif ftype == "clash":
            # å¤„ç† Clash èŠ‚ç‚¹æ–‡ä»¶
            proxies = data
            if not proxies:
                continue

            total = len(proxies)
            for idx, p in enumerate(proxies, start=1):
                flag, region = extract_region(p.get("name", ""))
                seq = str(idx).zfill(3 if total > 100 else 2)
                node_type = p.get("type", "Mix").upper()
                p["name"] = f"{EMOJI_PREFIX}{total}{node_type}{flag}{region}_{seq}"

            with open(output_file, "w", encoding="utf-8") as f:
                yaml.safe_dump({"proxies": proxies}, f, allow_unicode=True, sort_keys=False)

    print("âœ… èŠ‚ç‚¹æ–‡ä»¶å…¨éƒ¨å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    process_upstream_files()
